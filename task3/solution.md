##Deep Learning with Neural Networks<br>

As the name suggests the "Neural" part of a Neural Network is actually divised from our own body's master which is the Brain. Our brain consists of tiny cells called neurons which has 2 ends, One to take in input from other neurons and other to output information to the next neuron. Similarly these neurons are called "node" or "perceptron" to better differentiate then from actual neurons.

A Neural Netork has multiple "layers" for example, the first layer is called the input layer and the last layer is called the output layer. The middle layers are called "hidden" layers, they can add more complexity to our ML model to predict stuff better. Each node gets fed "weights" and "biases" which change will the model is getting trained so that the NN fits our data. They are then fed into a ACTIVATION FUNCTION which adds non-linearity into our model.

Then there are there are threshold functions which decides the classification of our data.They can be : ReLU(Rectified Linear Unit), Hyperbolic, Sigmoid or Linear.

All in all NNs can be made infinitely more complex but only find use cases for complex predictions like image classification and NLP. Using the right model for the right application is very crucial step in a ML Pipeline.